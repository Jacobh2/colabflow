{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Colabflow",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/Jacobh2/colabflow/blob/master/Colabflow.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "aUVcs-sn_a6y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "95055647-607f-4819-9ad8-e204ba015e8e"
      },
      "cell_type": "code",
      "source": [
        "print(\"Hello world! again\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hello world! again\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kLEQPGGz__1O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "outputId": "9597e7b0-4749-4214-9922-c6097cef1891"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import gc\n",
        "from AMSGrad import AMSGrad\n",
        "tf.logging.set_verbosity(tf.logging.INFO)\n",
        "\n",
        "from tqdm import tqdm\n",
        "from tqdm import trange\n",
        "\n",
        "from os import mkdir\n",
        "from os.path import abspath\n",
        "\n",
        "from random import choice\n",
        "from random import seed\n",
        "\n",
        "#from official.mnist import dataset as mnist\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets(\"./MNIST_data/\")\n",
        "\n",
        "tfd = tf.contrib.distributions\n",
        "\n",
        "EPOCH = 20\n",
        "BATCH_SIZE = 100\n",
        "SAMPLE_SIZE = 10\n",
        "STD_SAMPLE_RANGE=5\n",
        "LATENT_SPACE_STANDARD=10\n",
        "LEARNING_RATE=0.0005\n",
        "BETA_DISENTANGLE=100          #Set to 1 to \"turn off\"\n",
        "CAPACITY_CONTROL_MAX=15     #Set to 0 to \"turn off\"\n",
        "\n",
        "\n",
        "def make_prior(code_size=LATENT_SPACE_STANDARD):\n",
        "    with tf.name_scope('prior'):\n",
        "        mean = tf.zeros([code_size])\n",
        "        stddev = tf.ones([code_size])\n",
        "        return tfd.MultivariateNormalDiag(mean, stddev)\n",
        "\n",
        "\n",
        "def make_encoder(images, code_size=LATENT_SPACE_STANDARD):\n",
        "    with tf.name_scope('encoder'):\n",
        "        images = tf.layers.flatten(images)\n",
        "        hidden = tf.layers.dense(images, 200, tf.nn.relu)\n",
        "        hidden = tf.layers.dense(hidden, 200, tf.nn.relu)\n",
        "        mean = tf.layers.dense(hidden, code_size, name='encoder_mean')\n",
        "        stddev = tf.layers.dense(hidden, code_size, tf.nn.softplus, name='encoder_stddev')\n",
        "        return tfd.MultivariateNormalDiag(mean, stddev, name='mycoolname')\n",
        "\n",
        "\n",
        "def make_decoder(code, data_shape=[28, 28]):\n",
        "    with tf.name_scope('decoder'):\n",
        "        hidden = tf.layers.dense(code, 200, tf.nn.relu)\n",
        "        hidden = tf.layers.dense(hidden, 200, tf.nn.relu)\n",
        "        logit = tf.layers.dense(hidden, np.prod(data_shape))\n",
        "        logit = tf.reshape(logit, [-1] + data_shape)\n",
        "        return tfd.Independent(tfd.Bernoulli(logit), len(data_shape))\n",
        "\n",
        "def create_sample_codes_line(latent_dimentions, codes, beta, samples_per_dimention=20):\n",
        "    MIN = -STD_SAMPLE_RANGE\n",
        "    MAX = STD_SAMPLE_RANGE\n",
        "\n",
        "    #create coordinates holder\n",
        "    # coordinates = np.zeros((samples_per_dimention*latent_dimentions,latent_dimentions))\n",
        "\n",
        "    #coordinates = codes[:samples_per_dimention*latent_dimentions]\n",
        "    # print(codes[0].shape)\n",
        "    # print(np.mean(codes[0]))\n",
        "    # print(np.std(codes[0]))\n",
        "    seed(beta)\n",
        "    selected_image_from_batch = choice(codes)\n",
        "\n",
        "    coordinates = np.repeat([selected_image_from_batch],samples_per_dimention*latent_dimentions, axis=0)\n",
        "    #.reshape([samples_per_dimention*latent_dimentions,latent_dimentions])\n",
        "\n",
        "    #fill coordinates with linspace leaving all other values in same coordinate as zero\n",
        "    for i in range(latent_dimentions):\n",
        "        linspace_min = MIN + selected_image_from_batch[i]\n",
        "        linspace_max = MAX + selected_image_from_batch[i]\n",
        "\n",
        "        linspace = np.linspace(linspace_min, linspace_max, samples_per_dimention)\n",
        "\n",
        "\n",
        "        coordinates[i*samples_per_dimention:(i+1)*samples_per_dimention, i] = linspace\n",
        "        # Original:\n",
        "        #coordinates[i*samples_per_dimention:(i+1)*samples_per_dimention,i] = np.linspace(MIN, MAX, samples_per_dimention)\n",
        "\n",
        "        # New test:\n",
        "\n",
        "\n",
        "    return coordinates\n",
        "\n",
        "def create_sample_codes_mesh(latent_dimentions=2, samples_per_dimention=20):\n",
        "    MIN = -STD_SAMPLE_RANGE\n",
        "    MAX = STD_SAMPLE_RANGE\n",
        "\n",
        "    #create values for coordinates seperated on x values and y values\n",
        "    x,y=np.meshgrid(np.linspace(MIN, MAX, samples_per_dimention),np.linspace(MIN, MAX, samples_per_dimention))\n",
        "\n",
        "    #merge x and y-values to coordinates\n",
        "    coordinates=np.array(list(zip(x.ravel(),y.ravel())))\n",
        "    \n",
        "    return coordinates\n",
        "\n",
        "def plot_samples_batch(session, ax, coordinates, latent_dimentions=LATENT_SPACE_STANDARD, samples_per_dimention=20):\n",
        "    \n",
        "    #print(\"RUNNING IMAGES\")\n",
        "    # Run the values\n",
        "    all_images = session.run(decoder_output_reshaped, feed_dict={\n",
        "        decoder_input: coordinates\n",
        "    })\n",
        "    \n",
        "    #Prepare to order pictures by importance of neuron (i.e. importance for change of pixel)\n",
        "    order_value=list()\n",
        "    for i in range(latent_dimentions):\n",
        "        order_value.append((np.mean(np.square((all_images[i*samples_per_dimention]-all_images[(i+1)*samples_per_dimention-1]))),i))\n",
        "    #Aaaaaand the ordering itself\n",
        "    order_value.sort(reverse=True)\n",
        "    index_sorted = [x for _, x in order_value]\n",
        "\n",
        "    #print(\"PLOTTING\")\n",
        "    \n",
        "    for ax_index_x in range(latent_dimentions):\n",
        "        ax_x = ax[ax_index_x]\n",
        "        for ax_index_y in range(samples_per_dimention):\n",
        "            ax_x_y = ax_x[ax_index_y]\n",
        "            ax_x_y.imshow(all_images[index_sorted[ax_index_x]*samples_per_dimention+ax_index_y], cmap='gray')\n",
        "            ax_x_y.axis('off')\n",
        "\n",
        "# Skapa variant av input med annan shape\n",
        "images = tf.placeholder(tf.float32, [None, 28, 28])\n",
        "\n",
        "decoder_input = tf.placeholder(tf.float32, [None, LATENT_SPACE_STANDARD])\n",
        "\n",
        "capacity_control = tf.placeholder(tf.float32, ())\n",
        "beta_disentangle_var = tf.placeholder(tf.float32, ())\n",
        "\n",
        "# make_encoder = tf.make_template('encoder', make_encoder)\n",
        "# make_decoder = tf.make_template('decoder', make_decoder)\n",
        "\n",
        "# Gör vår 'prior' (att sample logit från)\n",
        "prior = make_prior()\n",
        "\n",
        "# encode:a input till en 'posterior'\n",
        "posterior = make_encoder(images)\n",
        "\n",
        "posterior_mean = posterior.mean()\n",
        "posterior_stddev = posterior.stddev()\n",
        "\n",
        "with tf.variable_scope(\"model\", reuse=False):\n",
        "    # Decode:a latent z men independent\n",
        "    code = posterior.sample()\n",
        "    dist = make_decoder(code)\n",
        "\n",
        "with tf.variable_scope(\"model\", reuse=True):\n",
        "    # Decode:a logit som vi samplar från och ta dess mean\n",
        "    sample = make_decoder(prior.sample(10)).mean() # for visualization\n",
        "\n",
        "with tf.variable_scope(\"model\", reuse=True):\n",
        "    # Decode:a logit som vi samplar från och ta dess mean\n",
        "    decoder_output = make_decoder(decoder_input).mean() # for visualization\n",
        "    decoder_output_reshaped = tf.reshape(decoder_output, [-1, 28, 28])\n",
        "\n",
        "# Evidence Lower BOund (cost-fn)\n",
        "elbo = tf.reduce_mean(dist.log_prob(images) - beta_disentangle_var * tf.abs(tfd.kl_divergence(posterior, prior)-capacity_control))\n",
        "\n",
        "# Skapa optimerare (Adam) och minimera \n",
        "#optimize = tf.train.AdamOptimizer(LEARNING_RATE).minimize(-elbo)\n",
        "optimize = AMSGrad(learning_rate=LEARNING_RATE, beta1=0.9, beta2=0.99, epsilon=1e-8).minimize(-elbo)\n",
        "\n",
        "training_data = mnist.train\n",
        "test_data = mnist.test\n",
        "\n",
        "def run(filename='./ascoolt3.png', beta=BETA_DISENTANGLE, t=None):\n",
        "\n",
        "    try:\n",
        "        asb_path = '/'.join(abspath(filename).split('/')[:-1])\n",
        "        mkdir(asb_path)\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    latent_dimentions=LATENT_SPACE_STANDARD\n",
        "    samples_per_dimention=20\n",
        "\n",
        "    with tf.Session() as session:\n",
        "        session.run(tf.global_variables_initializer())\n",
        "        test_elbo=None\n",
        "        for epoch in range(EPOCH):\n",
        "            \n",
        "            if t:\n",
        "                t.set_postfix(epoch=epoch, beta=beta)\n",
        "\n",
        "            test_elbo,test_codes=session.run([elbo,code], feed_dict={\n",
        "                    images: test_data.images.reshape([-1, 28, 28]), \n",
        "                    capacity_control: (CAPACITY_CONTROL_MAX*(epoch+1)/EPOCH),\n",
        "                    beta_disentangle_var: beta})\n",
        "            #print(elbo)\n",
        "            for train_step in range(training_data.num_examples//BATCH_SIZE):\n",
        "                image_data, label = training_data.next_batch(BATCH_SIZE)\n",
        "                session.run(optimize, feed_dict={\n",
        "                    images: image_data.reshape([-1, 28, 28]), \n",
        "                    capacity_control: (CAPACITY_CONTROL_MAX*(epoch+1)/EPOCH),\n",
        "                    beta_disentangle_var: beta})\n",
        "\n",
        "        coordinates = create_sample_codes_line(latent_dimentions,test_codes, beta)\n",
        "        fig, ax = plt.subplots(nrows=int(coordinates.shape[0]/samples_per_dimention), ncols=samples_per_dimention,\n",
        "                figsize=((samples_per_dimention, int(coordinates.shape[0]/samples_per_dimention))))\n",
        "        plot_samples_batch(session, ax, coordinates)\n",
        "    \n",
        "    plt.savefig(filename, dpi=300, transparent=True, bbox_inches='tight')\n",
        "    #print(\"Picture saved!\")\n",
        "    #plt.show()\n",
        "        # for i in range(SAMPLE_SIZE):\n",
        "        #     image = tf.reshape(sample[i],[28,28])\n",
        "        #     image = session.run(image)\n",
        "        #     plt.imshow(image, cmap='gray')  \n",
        "        #     plt.show()\n",
        "\n",
        "def gridsearch_beta():\n",
        "    #With capacity control\n",
        "    for i in tqdm(range(0,100,10), desc=\"Total process\", unit=\"configs\"):\n",
        "        run('./beta/' + str(i) + 'capcont.png', beta=i)\n",
        "    #Without capacity control\n",
        "    global CAPACITY_CONTROL_MAX\n",
        "    CAPACITY_CONTROL_MAX=0\n",
        "    for i in tqdm(range(0,100,10), desc=\"Total process\", unit=\"configs\"):\n",
        "        run(filename='./beta/' + str(i) + '.png', beta=i)\n",
        "        gc.collect()\n",
        "\n",
        "\n",
        "def random_search_beta(MIN=15,MAX=50,INSTANCES=5):\n",
        "    search_points=list(np.random.choice(range(MIN,MAX),INSTANCES,replace=False))\n",
        "    print(\"Söker av beta =\", search_points)\n",
        "    #With capacity control\n",
        "    with trange(len(search_points), desc='Total Networks', unit='Configs') as t:\n",
        "        for ii in t:\n",
        "            i = search_points[ii]\n",
        "            t.set_description('BETA %i' % i)\n",
        "            # for i in tqdm(search_points, desc=\"Total process\", unit=\"configs\"):\n",
        "            run('./beta/' + str(i) + 'capcont.png', beta=i, t=t)\n",
        "    #Without capacity control\n",
        "    global CAPACITY_CONTROL_MAX\n",
        "    CAPACITY_CONTROL_MAX=0\n",
        "    with trange(len(search_points), desc='Total Networks', unit='Configs') as t:\n",
        "        for ii in t:\n",
        "            i = search_points[ii]\n",
        "            t.set_description('BETA %i' % i)\n",
        "            # for i in tqdm(search_points, desc=\"Total process\", unit=\"configs\"):\n",
        "            run(filename='./beta/' + str(i) + '.png', beta=i, t=t)\n",
        "            # gc.collect()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # print(\"A\", dir(posterior))\n",
        "    # print(\"B\", posterior.mean())\n",
        "    # print(\"C\", posterior.stddev())\n",
        "    # print(\"TEST IMAGES:\", mnist.test.labels)\n",
        "    #run()\n",
        "    #gridsearch_beta()\n",
        "    random_search_beta()\n",
        "    # for i in tf.trainable_variables():\n",
        "    #     print(\"VAR:\", i)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-b449e6071946>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mAMSGrad\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAMSGrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_verbosity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINFO\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'AMSGrad'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}